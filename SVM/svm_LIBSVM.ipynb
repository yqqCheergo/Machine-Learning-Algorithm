{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24cfdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装命令：pip install -U libsvm-official --trusted-host pypi.tuna.tsinghua.edu.cn\n",
    "from libsvm.svmutil import *\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e26e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_read_mat(file_name):   \n",
    "    num_list = []\n",
    "    \n",
    "    with open(file_name,\"r\",encoding='UTF-8') as file:\n",
    "        for l in file:\n",
    "            l = l.split(',')  # l为列表类型\n",
    "            \n",
    "            list_k = []\n",
    "            for j in range(3):\n",
    "                # [a,1,b,3,c,2,draw]为例，经过下面代码将会变为[0, 1, 1, 3, 2, 2]\n",
    "                '''ord()函数用于将字符转换为整数'''\n",
    "                list_k.append(ord(l[j*2]) - ord('a'))   # 0、2、4位是字母。将字母a化为数字0，以此类推\n",
    "                list_k.append(ord(l[j*2 + 1]) - ord('0'))  # 数字位还是保留原来的数字\n",
    "                \n",
    "            if(l[6][0] == 'd'):\n",
    "                list_k.append(1)   # draw为正样本\n",
    "            else:\n",
    "                list_k.append(-1)    # 其余情况都为负样本\n",
    "                \n",
    "            num_list.append(list_k)  # 此时list_k中第一条为[a,1,b,3,c,2,draw] ——> [0, 1, 1, 3, 2, 2, 1]\n",
    "            \n",
    "    num_mat = np.array(num_list,dtype=\"float\")\n",
    "    '''\n",
    "    在此处是以numpy的二维数据矩阵的形式存储的，本以为使用numpy的数据进行运算可以使得\n",
    "    训练的速度快一些，结果发现如果要往libsvm中的函数传入参数只能传入list型，不能传入numpy\n",
    "    的数据类型。所以，后面又把数据类型转回了list型\n",
    "    '''\n",
    "    return num_mat   # 返回一个n*7的矩阵，前6列是三个坐标，第七列是标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5c22eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_deal(mat, len_train, len1, len_test, len2):\n",
    "    '''\n",
    "    mat: 大矩阵，其中包括训练数据和测试数据\n",
    "    len_train:训练数据   5000\n",
    "    len1: 输入坐标  6\n",
    "    len_test: 测试数据\n",
    "    len2: 标签  1\n",
    "    '''\n",
    "    np.random.shuffle(mat)  # 先将矩阵按行打乱\n",
    "    # 然后根据要求对矩阵进行分割，第一部分是训练集，第二部分是测试集\n",
    "    x_part1 = mat[0:len_train, 0:len1]   # 训练数据的坐标，shape为(5000,6)\n",
    "    x_part2 = mat[len_train:, 0:len1]    # 测试数据的坐标\n",
    "    y_part1 = mat[0:len_train, len1]     # 训练数据的标签\n",
    "    y_part2 = mat[len_train:, len1]      # 测试数据的标签\n",
    "    \n",
    "    # 样本归一化：在训练样本上求出每个维度的均值和标准差，在训练和测试样本上同时归一化\n",
    "    avgX = np.mean(x_part1, axis=0)    # axis=0，计算每一列的均值\n",
    "    stdX = np.std(x_part1, axis=0)\n",
    "    \n",
    "    # 将训练集和测试集都进行归一化处理\n",
    "    for data in x_part1:   # 训练集 (5000，6)\n",
    "        for j in range(len(data)):   # j为0~5\n",
    "            data[j] = (data[j] - avgX[j]) / stdX[j]\n",
    "    for data in x_part2:   # 测试集\n",
    "        for j in range(len(data)):\n",
    "            data[j] = (data[j] - avgX[j]) / stdX[j]\n",
    "\n",
    "    return x_part1, y_part1, x_part2, y_part2   # 返回的依次是训练数据，训练数据的标签，测试数据，测试数据的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8908be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(CScale, gammaScale, prob):\n",
    "    '''\n",
    "    CScale: 参数C的取值序列\n",
    "    gammaScale: 参数γ的取值序列\n",
    "    prob: 训练集合对应的标签\n",
    "    '''\n",
    "    maxACC = 0             # 最高正确率\n",
    "    maxACC_C = 0           # 最优参数C\n",
    "    maxACC_gamma = 0       # 最优参数γ\n",
    " \n",
    "    # 嵌套循环\n",
    "    for C in CScale:\n",
    "        C_ = pow(2, C)  # 2的C次方\n",
    "        for gamma in gammaScale:\n",
    "            gamma_ = pow(2, gamma)  # 2的gamma次方\n",
    "            \n",
    "            # 设置训练的参数，其中-q表示静默模式，不输出训练过程信息\n",
    "            param = svm_parameter('-t 2 -c ' + str(C_) + ' -g ' + str(gamma_) + ' -v 5 -q')\n",
    "            ACC = svm_train(prob, param)  # 进行训练，但是传回的不是训练模型而是5折交叉验证的准确率\n",
    "            \n",
    "            # 更新数据\n",
    "            if (ACC > maxACC):\n",
    "                maxACC = ACC\n",
    "                maxACC_C = C\n",
    "                maxACC_gamma = gamma\n",
    "                \n",
    "    return maxACC, maxACC_C, maxACC_gamma  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7213cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewList(L, U, step):   \n",
    "    l = []\n",
    "    while(L < U):\n",
    "        l.append(L)\n",
    "        L += step\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c20b1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModelSVM(data, label, iter, model_file):\n",
    "    '''\n",
    "    data: 数据\n",
    "    label: 标签\n",
    "    iter: 训练次数，在原先的MATLAB代码中的次数是两次\n",
    "    model_file: 模型的保存位置\n",
    "    '''\n",
    "    \n",
    "    # 将数据转换成list型的数据。因为在svm的函数中好像只能传入list型的数据进行训练使用\n",
    "    X = data.tolist()\n",
    "    Y = label.tolist()\n",
    "    \n",
    "    CScale = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]     # 参数C的取值为2^C\n",
    "    gammaScale = [-15, -13, -11, -9, -7, -5, -3, -1, 1, 3]   # 参数γ的取值为2^γ\n",
    "    cnt = iter\n",
    "    step = 2  # 用于重新生成CScale和gammaScale序列\n",
    "    maxACC = 0         # 训练过程中的最大正确率\n",
    "    bestACC_C = 0      # 训练过程中的最优参数C\n",
    "    bestACC_gamma = 0  # 训练过程中的最优参数γ\n",
    "    prob = svm_problem(Y, X)  # 传入数据\n",
    "    \n",
    "    while(cnt):\n",
    "        # 用传入的参数序列进行训练，返回的是此次训练的最高正确率、最优参数C、最优参数γ\n",
    "        maxACC_train, maxACC_C_train, maxACC_gamma_train = TrainModel(CScale, gammaScale, prob)   # prob为训练集合对应的标签\n",
    "        # 数据更新\n",
    "        if(maxACC_train > maxACC):\n",
    "            maxACC = maxACC_train\n",
    "            bestACC_C = maxACC_C_train\n",
    "            bestACC_gamma = maxACC_gamma_train\n",
    "            \n",
    "        # 根据返回的参数重新生成CScale序列和gammaScale序列用于再次训练，下一次训练的C参数和γ参数的精度会比之前更高\n",
    "        # step就是CScale序列和gammaScale序列相邻两个数之间的间隔\n",
    "        new_step = step*2/10\n",
    "        CScale = getNewList(maxACC_C_train - step, maxACC_C_train + step + new_step, new_step)\n",
    "        gammaScale = getNewList(maxACC_gamma_train - step, maxACC_gamma_train + step + new_step, new_step)\n",
    "        cnt -= 1\n",
    "        \n",
    "    # 获得最优参数后计算出对应的C和γ，并且训练获得最优模型\n",
    "    C = pow(2, bestACC_C)\n",
    "    gamma = pow(2, bestACC_gamma)\n",
    "    param = svm_parameter('-t 2 -c ' + str(C) + ' -g ' + str(gamma))\n",
    "    model = svm_train(prob, param)    # 准确率\n",
    "    svm_save_model(model_file, model) # 保存模型\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baee3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_file = r\"D:\\Jupyter Notebook\\SVM\\krkopt.data\"  # 数据存放的位置\n",
    "    mode_file = r\"D:\\Jupyter Notebook\\SVM\\model_file\"   # 训练模型保存的位置\n",
    "    data_mat = data_read_mat(data_file)  # 从文件中读取数据并处理\n",
    "    \n",
    "    # 以下是对训练数据进行分配\n",
    "    train = 5000   # 5000组数据作为训练数据\n",
    "    test  = len(data_mat) - 5000  # 剩下的数据（23056组）作为测试数据\n",
    "    x_len = 6   # 输入数据的维度是6维，即三个棋子的坐标\n",
    "    y_len = len(data_mat[0]) - x_len  # 输出的数据是1维，即两种结果\n",
    "    iter = 2   # 训练的次数，训练的次数越多，参数就调整的精度越高\n",
    "    x_train, y_train, x_test, y_test = data_deal(data_mat, train, x_len, test, y_len)   # 对数据进行分割\n",
    "    \n",
    "    if (input(\"是否需要进行训练？\") == 'y'):  # 如果输入y就会进行训练，否则就可以直接使用之前训练完成的模型\n",
    "        model = TrainModelSVM(x_train, y_train, iter, mode_file)  # 传入输入数据、标签进行模型的训练\n",
    "    else:\n",
    "        model = svm_load_model(mode_file)  # 直接加载现有模型\n",
    "        \n",
    "    X = x_test.tolist()  # 将测试集的坐标转换成list\n",
    "    Y = y_test.tolist()  # 将测试集的标签转换成list\n",
    "    # print(Y[:])\n",
    "    p_labs, p_acc, p_vals = svm_predict(Y, X, model)\n",
    "    \n",
    "    fpr, tpr, threshold = roc_curve(y_test, p_labs)  # 计算真正率tpr和假正率fpr\n",
    "    roc_auc = auc(fpr, tpr)  # 计算auc的值，auc就是曲线包围的面积，越大越好\n",
    "    print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d28d195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是否需要进行训练？y\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 91.94%\n",
      "Cross Validation Accuracy = 91.02%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 92.62%\n",
      "Cross Validation Accuracy = 97.14%\n",
      "Cross Validation Accuracy = 95.96%\n",
      "Cross Validation Accuracy = 90.34%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.16%\n",
      "Cross Validation Accuracy = 98.68%\n",
      "Cross Validation Accuracy = 98.66%\n",
      "Cross Validation Accuracy = 95.82%\n",
      "Cross Validation Accuracy = 90.46%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 97.06%\n",
      "Cross Validation Accuracy = 99.34%\n",
      "Cross Validation Accuracy = 98.74%\n",
      "Cross Validation Accuracy = 96.1%\n",
      "Cross Validation Accuracy = 90.5%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.42%\n",
      "Cross Validation Accuracy = 99.32%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 98.68%\n",
      "Cross Validation Accuracy = 95.96%\n",
      "Cross Validation Accuracy = 90.34%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 98.46%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 98.88%\n",
      "Cross Validation Accuracy = 96.02%\n",
      "Cross Validation Accuracy = 90.38%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.56%\n",
      "Cross Validation Accuracy = 99.36%\n",
      "Cross Validation Accuracy = 99.34%\n",
      "Cross Validation Accuracy = 99.04%\n",
      "Cross Validation Accuracy = 98.98%\n",
      "Cross Validation Accuracy = 95.92%\n",
      "Cross Validation Accuracy = 90.3%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 98.84%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.36%\n",
      "Cross Validation Accuracy = 99.2%\n",
      "Cross Validation Accuracy = 98.8%\n",
      "Cross Validation Accuracy = 95.9%\n",
      "Cross Validation Accuracy = 90.38%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.08%\n",
      "Cross Validation Accuracy = 90.8%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.34%\n",
      "Cross Validation Accuracy = 98.9%\n",
      "Cross Validation Accuracy = 99.14%\n",
      "Cross Validation Accuracy = 98.78%\n",
      "Cross Validation Accuracy = 96.18%\n",
      "Cross Validation Accuracy = 90.44%\n",
      "Cross Validation Accuracy = 90.64%\n",
      "Cross Validation Accuracy = 93.82%\n",
      "Cross Validation Accuracy = 97.26%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.34%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 92.36%\n",
      "Cross Validation Accuracy = 95.5%\n",
      "Cross Validation Accuracy = 98.52%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.36%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 94.18%\n",
      "Cross Validation Accuracy = 97.36%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.36%\n",
      "Cross Validation Accuracy = 99.32%\n",
      "Cross Validation Accuracy = 99.28%\n",
      "Cross Validation Accuracy = 95.38%\n",
      "Cross Validation Accuracy = 98.66%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.3%\n",
      "Cross Validation Accuracy = 99.3%\n",
      "Cross Validation Accuracy = 97.16%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.32%\n",
      "Cross Validation Accuracy = 99.28%\n",
      "Cross Validation Accuracy = 99.34%\n",
      "Cross Validation Accuracy = 98.86%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.34%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.32%\n",
      "Cross Validation Accuracy = 99.34%\n",
      "Cross Validation Accuracy = 99.1%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.44%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.34%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.3%\n",
      "Cross Validation Accuracy = 99.18%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.44%\n",
      "Cross Validation Accuracy = 99.38%\n",
      "Cross Validation Accuracy = 99.36%\n",
      "Cross Validation Accuracy = 99.2%\n",
      "Cross Validation Accuracy = 99.08%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.36%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.36%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.36%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.26%\n",
      "Cross Validation Accuracy = 99.2%\n",
      "Cross Validation Accuracy = 99.14%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.34%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.44%\n",
      "Cross Validation Accuracy = 99.24%\n",
      "Cross Validation Accuracy = 99.3%\n",
      "Cross Validation Accuracy = 99.1%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.4%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.42%\n",
      "Cross Validation Accuracy = 99.34%\n",
      "Cross Validation Accuracy = 99.32%\n",
      "Cross Validation Accuracy = 99.34%\n",
      "Cross Validation Accuracy = 99.26%\n",
      "Cross Validation Accuracy = 99.02%\n",
      "Cross Validation Accuracy = 98.98%\n",
      "Accuracy = 99.3668% (22910/23056) (classification)\n",
      "0.9945499258464813\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be489d6",
   "metadata": {},
   "source": [
    "### 博客：https://zhuanlan.zhihu.com/p/537715035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f688a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
